{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG-QA System: Question Answering on AI Research Papers\n",
    "\n",
    "This notebook demonstrates a production-grade Retrieval-Augmented Generation (RAG) system for answering questions about seminal AI research papers.\n",
    "\n",
    "## Features\n",
    "- **Hybrid Chunking**: Semantic-first chunking with fixed-size fallback\n",
    "- **Dual Embedding System**: Compare OpenAI vs open-source (BGE) embeddings\n",
    "- **Hybrid Retrieval**: BM25 + Dense retrieval with Reciprocal Rank Fusion\n",
    "- **Cross-Encoder Reranking**: Fine-grained relevance scoring\n",
    "- **Source Attribution**: Both inline citations and structured source metadata\n",
    "\n",
    "## Research Papers\n",
    "| Paper | Authors | Year |\n",
    "|-------|---------|------|\n",
    "| Attention Is All You Need | Vaswani et al. | 2017 |\n",
    "| RAG for Knowledge-Intensive NLP | Lewis et al. | 2020 |\n",
    "| Language Models are Few-Shot Learners | Brown et al. | 2020 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Clone the repository\n# Note: Update branch to 'main' after merging the feature branch\n!git clone -b claude/extract-root-files-wm4Kj https://github.com/crowbarmassage/rag-research-qa.git\n%cd rag-research-qa\n\n# Verify we have the source code\n!ls -la src/"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Install dependencies from requirements.txt\n!pip install -q -r requirements.txt\n\n# Verify key packages\nimport importlib\nfor pkg in ['pdfplumber', 'chromadb', 'sentence_transformers', 'openai', 'fastapi']:\n    if importlib.util.find_spec(pkg):\n        print(f\"âœ“ {pkg}\")\n    else:\n        print(f\"âœ— {pkg} - installation failed\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up environment variables\n",
    "import os\n",
    "from google.colab import userdata\n",
    "\n",
    "# Option 1: Using Colab Secrets (recommended)\n",
    "try:\n",
    "    os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
    "    print(\"âœ“ API key loaded from Colab Secrets\")\n",
    "except:\n",
    "    # Option 2: Manual entry\n",
    "    os.environ['OPENAI_API_KEY'] = 'sk-your-key-here'  # Replace with your key\n",
    "    print(\"âš  Please set your OpenAI API key above\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Document Preprocessing\n",
    "\n",
    "This section demonstrates:\n",
    "- PDF text extraction using pdfplumber\n",
    "- Section boundary detection\n",
    "- Hybrid chunking (semantic + fixed-size fallback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Upload PDF files (not included in repo due to size)\nfrom google.colab import files\nimport os\n\n# Create papers directory\nos.makedirs('data/papers', exist_ok=True)\n\nprint(\"ğŸ“„ Please upload the 3 research paper PDFs:\")\nprint(\"   1. 1706.03762v7.pdf - Attention Is All You Need (Vaswani et al.)\")\nprint(\"   2. 2005.11401v4.pdf - RAG Paper (Lewis et al.)\")\nprint(\"   3. 2005.14165v4.pdf - GPT-3 Paper (Brown et al.)\")\nprint()\nprint(\"You can download these from arXiv:\")\nprint(\"   https://arxiv.org/abs/1706.03762\")\nprint(\"   https://arxiv.org/abs/2005.11401\")\nprint(\"   https://arxiv.org/abs/2005.14165\")\nprint()\n\nuploaded = files.upload()\n\n# Move to data/papers/\nfor filename in uploaded.keys():\n    dest = f'data/papers/{filename}'\n    if os.path.exists(filename):\n        os.rename(filename, dest)\n        print(f\"âœ“ Saved {filename} to data/papers/\")\n    \nprint(f\"\\nâœ“ {len(uploaded)} files uploaded to data/papers/\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate PDF parsing\n",
    "from pathlib import Path\n",
    "from src.preprocessing import CompositeParser, SectionDetector, HybridChunker\n",
    "\n",
    "parser = CompositeParser()\n",
    "section_detector = SectionDetector()\n",
    "chunker = HybridChunker()\n",
    "\n",
    "# Parse one paper as example\n",
    "papers_dir = Path('data/papers')\n",
    "pdf_files = list(papers_dir.glob('*.pdf'))\n",
    "\n",
    "if pdf_files:\n",
    "    sample_pdf = pdf_files[0]\n",
    "    print(f\"\\nğŸ“„ Parsing: {sample_pdf.name}\")\n",
    "    \n",
    "    # Extract document\n",
    "    doc = parser.extract(sample_pdf)\n",
    "    print(f\"   Title: {doc.metadata.title[:60]}...\")\n",
    "    print(f\"   Pages: {doc.metadata.total_pages}\")\n",
    "    \n",
    "    # Detect sections\n",
    "    sections = section_detector.detect_sections(doc.full_text, doc.pages)\n",
    "    print(f\"   Sections detected: {len(sections)}\")\n",
    "    print(f\"   Sample sections: {[s.title for s in sections[:5]]}\")\n",
    "    \n",
    "    # Chunk document\n",
    "    chunks = chunker.chunk_document(doc, sections)\n",
    "    print(f\"   Chunks created: {len(chunks)}\")\n",
    "    \n",
    "    # Show sample chunk\n",
    "    print(f\"\\nğŸ“¦ Sample Chunk:\")\n",
    "    print(f\"   Section: {chunks[0].section_title}\")\n",
    "    print(f\"   Tokens: {chunks[0].token_count}\")\n",
    "    print(f\"   Content: {chunks[0].content[:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Index All Documents\n",
    "\n",
    "Index all papers into dual vector stores (OpenAI + open-source embeddings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the indexing script\n",
    "!python scripts/index_documents.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Initialize RAG Pipeline\n",
    "\n",
    "Load the indexed documents and initialize the full RAG pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.pipeline import RAGPipeline\n",
    "\n",
    "# Initialize pipeline from indexed documents\n",
    "pipeline = RAGPipeline.from_documents(\n",
    "    embedding_provider=\"openai\",\n",
    "    use_reranker=True\n",
    ")\n",
    "\n",
    "# Show stats\n",
    "stats = pipeline.get_document_stats()\n",
    "print(f\"\\nâœ“ Pipeline initialized\")\n",
    "print(f\"  Total chunks: {stats['total_chunks']}\")\n",
    "print(f\"  Documents:\")\n",
    "for doc in stats['documents']:\n",
    "    print(f\"    - {doc['title']}: {doc['total_chunks']} chunks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Retrieval System Demo\n",
    "\n",
    "Demonstrate the hybrid retrieval system:\n",
    "- Dense retrieval (vector similarity)\n",
    "- Sparse retrieval (BM25)\n",
    "- Reciprocal Rank Fusion\n",
    "- Cross-encoder reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo: Compare retrieval methods\n",
    "query = \"What is multi-head attention?\"\n",
    "\n",
    "print(f\"Query: {query}\\n\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Get results from different methods\n",
    "dense_results = pipeline.retrieve_only(query, top_k=3, method=\"dense\")\n",
    "sparse_results = pipeline.retrieve_only(query, top_k=3, method=\"sparse\")\n",
    "hybrid_results = pipeline.retrieve_only(query, top_k=3, method=\"hybrid\")\n",
    "\n",
    "print(\"\\nğŸ“Š Dense Retrieval (Vector Similarity):\")\n",
    "for i, r in enumerate(dense_results, 1):\n",
    "    print(f\"  [{i}] {r['metadata']['doc_id']} - {r['metadata']['section_title']}\")\n",
    "    print(f\"      Score: {r['score']:.4f}\")\n",
    "\n",
    "print(\"\\nğŸ“Š Sparse Retrieval (BM25):\")\n",
    "for i, r in enumerate(sparse_results, 1):\n",
    "    print(f\"  [{i}] {r['metadata']['doc_id']} - {r['metadata']['section_title']}\")\n",
    "    print(f\"      Score: {r['score']:.4f}\")\n",
    "\n",
    "print(\"\\nğŸ“Š Hybrid Retrieval (RRF + Reranking):\")\n",
    "for i, r in enumerate(hybrid_results, 1):\n",
    "    print(f\"  [{i}] {r['metadata']['doc_id']} - {r['metadata']['section_title']}\")\n",
    "    print(f\"      Score: {r['score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo: Compare OpenAI vs Open-source embeddings\n",
    "comparison = pipeline.compare_embeddings(\n",
    "    question=\"How does positional encoding work?\",\n",
    "    top_k=5\n",
    ")\n",
    "\n",
    "print(f\"Query: {comparison['query']}\\n\")\n",
    "print(f\"Agreement Score: {comparison['agreement_score']:.0%}\")\n",
    "print(\"(Percentage of top-5 results that overlap between providers)\\n\")\n",
    "\n",
    "print(\"OpenAI Embedding Results:\")\n",
    "for r in comparison['openai_results'][:3]:\n",
    "    print(f\"  - {r['metadata']['section_title']} (score: {r['score']:.4f})\")\n",
    "\n",
    "print(\"\\nOpen-source (BGE) Embedding Results:\")\n",
    "for r in comparison['opensource_results'][:3]:\n",
    "    print(f\"  - {r['metadata']['section_title']} (score: {r['score']:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Answer Generation with Source Attribution\n",
    "\n",
    "Generate answers using the full RAG pipeline with:\n",
    "- Context assembly from retrieved chunks\n",
    "- LLM generation (gpt-4o-mini)\n",
    "- Inline citations\n",
    "- Structured source attribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_answer(response):\n",
    "    \"\"\"Display a formatted answer response.\"\"\"\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"â“ Question: {response.question}\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"\\nğŸ“ Answer:\\n{response.answer}\")\n",
    "    print(f\"\\n\" + \"-\" * 70)\n",
    "    print(f\"ğŸ“Š Metadata:\")\n",
    "    print(f\"   Confidence: {response.confidence:.1%}\")\n",
    "    print(f\"   Method: {response.retrieval_method}\")\n",
    "    print(f\"   Time: {response.processing_time_ms:.0f}ms\")\n",
    "    print(f\"\\nğŸ“š Sources ({len(response.sources)}):\")\n",
    "    for s in response.sources:\n",
    "        print(f\"   [{s.source_index}] {s.paper_title}\")\n",
    "        if s.section:\n",
    "            print(f\"       Section: {s.section}\")\n",
    "        if s.page_numbers:\n",
    "            print(f\"       Pages: {s.page_numbers}\")\n",
    "        print(f\"       Relevance: {s.relevance_score:.1%}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Sample Questions with Outputs\n",
    "\n",
    "Running all 5 required sample questions with full source attribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 1\n",
    "q1 = \"What are the main components of a RAG model, and how do they interact?\"\n",
    "response1 = pipeline.answer(q1, retrieval_method=\"hybrid\", top_k=5)\n",
    "display_answer(response1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 2\n",
    "q2 = \"What are the two sub-layers in each encoder layer of the Transformer model?\"\n",
    "response2 = pipeline.answer(q2, retrieval_method=\"hybrid\", top_k=5)\n",
    "display_answer(response2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 3\n",
    "q3 = \"Explain how positional encoding is implemented in Transformers and why it is necessary.\"\n",
    "response3 = pipeline.answer(q3, retrieval_method=\"hybrid\", top_k=5)\n",
    "display_answer(response3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 4\n",
    "q4 = \"Describe the concept of multi-head attention in the Transformer architecture. Why is it beneficial?\"\n",
    "response4 = pipeline.answer(q4, retrieval_method=\"hybrid\", top_k=5)\n",
    "display_answer(response4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 5\n",
    "q5 = \"What is few-shot learning, and how does GPT-3 implement it during inference?\"\n",
    "response5 = pipeline.answer(q5, retrieval_method=\"hybrid\", top_k=5)\n",
    "display_answer(response5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Evaluation Metrics\n",
    "\n",
    "Evaluate retrieval quality with Precision@5 and Mean Reciprocal Rank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run evaluation\n",
    "!python scripts/evaluate.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Architecture Overview\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                           RAG-QA SYSTEM ARCHITECTURE                        â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                             â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚\n",
    "â”‚  â”‚   PDF       â”‚    â”‚           DOCUMENT PREPROCESSING                  â”‚   â”‚\n",
    "â”‚  â”‚   Files     â”‚â”€â”€â”€â–¶â”‚  PDF Parser â”€â–¶ Section Detector â”€â–¶ Hybrid Chunkerâ”‚   â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚\n",
    "â”‚                                          â”‚                                  â”‚\n",
    "â”‚                                          â–¼                                  â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚\n",
    "â”‚  â”‚                    DUAL EMBEDDING PIPELINE                            â”‚  â”‚\n",
    "â”‚  â”‚     OpenAI (text-embedding-3-small)  |  BGE (bge-base-en-v1.5)       â”‚  â”‚\n",
    "â”‚  â”‚              â–¼                                    â–¼                   â”‚  â”‚\n",
    "â”‚  â”‚     ChromaDB Collection              ChromaDB Collection              â”‚  â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚\n",
    "â”‚                                          â”‚                                  â”‚\n",
    "â”‚                                          â–¼                                  â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚\n",
    "â”‚  â”‚                    HYBRID RETRIEVAL ENGINE                            â”‚  â”‚\n",
    "â”‚  â”‚  Dense Retrieval + BM25 Sparse â”€â–¶ RRF Fusion â”€â–¶ Cross-Encoder Rerank â”‚  â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚\n",
    "â”‚                                          â”‚                                  â”‚\n",
    "â”‚                                          â–¼                                  â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚\n",
    "â”‚  â”‚                    ANSWER GENERATION                                  â”‚  â”‚\n",
    "â”‚  â”‚    Context Assembly â”€â–¶ LLM (gpt-4o-mini) â”€â–¶ Citation Formatter       â”‚  â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚\n",
    "â”‚                                          â”‚                                  â”‚\n",
    "â”‚                                          â–¼                                  â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚\n",
    "â”‚  â”‚                    OUTPUT: Answer + Source Attribution                â”‚  â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary\n",
    "\n",
    "### What We Built\n",
    "- **Document Preprocessing**: PDF parsing, section detection, hybrid chunking\n",
    "- **Dual Embedding System**: OpenAI + open-source BGE embeddings\n",
    "- **Hybrid Retrieval**: BM25 + dense + RRF + cross-encoder reranking\n",
    "- **Answer Generation**: gpt-4o-mini with source attribution\n",
    "- **API**: FastAPI with 6 endpoints\n",
    "\n",
    "### Performance\n",
    "- Retrieval Precision@5: **100%**\n",
    "- Mean Reciprocal Rank: **1.000**\n",
    "- 335 chunks from 3 research papers\n",
    "\n",
    "### Repository\n",
    "- GitHub: https://github.com/crowbarmassage/rag-research-qa\n",
    "- 59 passing tests\n",
    "- Full documentation in README.md, TECH_SPECS.md, ATOMIC_STEPS.md"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}